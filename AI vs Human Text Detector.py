import gradio as gr
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch

# Load a pre-trained/fine-tuned model (Replace this with your own model if needed)
MODEL_NAME = "roberta-base-openai-detector"  # Replace with your own if available
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)

# Function to predict AI vs Human content
def detect_origin(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.nn.functional.softmax(outputs.logits, dim=1)
        ai_score = round(probs[0][1].item() * 100, 2)
        human_score = round(100 - ai_score, 2)
        return f"ðŸ§  AI Likelihood: {ai_score}%\nðŸ‘¤ Human Likelihood: {human_score}%"

# Gradio Interface
iface = gr.Interface(
    fn=detect_origin,
    inputs=gr.Textbox(lines=10, placeholder="Paste your text here..."),
    outputs="text",
    title="AI vs Human Text Detector",
    description="This tool detects whether the given text was likely written by a human or generated by AI.",
)

# Launch app
iface.launch()
